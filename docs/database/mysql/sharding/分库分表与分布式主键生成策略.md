<div style="text-align: center;"><h1>分库分表与分布式主键生成策略</h1></div>

主键生成策略，这是一个小问题，但却是一个大世界。很多人开发几十年都没有去想过这个问题，觉得有框架拿来用就是了。但是其实他一点都不简单。正好ShardingSphere5.x版本新集成了一个新的主键生成框架，CosId。这框架功能很强大，性能据说也非常高。只是目前还不太好用，有很多小问题。尤其是与周边生态的版本冲突，简直让人抓狂。官方资料也比较少。因此，如果你想要在大型项目中真正用上CosID，那么，我的建议是，最好先确定自己对于CosID有几把刷子，要不然，就等着被各种莫名其妙的错误折磨得死去活来把。

这里就正好借着梳理CosID的机会，好好把分布式主键生成策略给梳理一下。相信把基础思想梳理清楚了之后，再去了解CosId就比较简单了。

# 一、从分库分表的一个神坑说起

我想要将一个表的数据分到两个库中的两个表，共四个分片。这应该是分库分表中最为典型的一个场景了。

![](./asserts/5.1.png)

Course课程信息按照cid字段进行分片，那么分库的算法可以简单设置为按cid奇偶拆分，定制算法m$->{cid%2}就行了。而分表的算法呢？如果也是简单的按照cid奇偶拆分，算法定制为course_$->{cid%2+1}。这个时候，所有的Course课程记录，实际上只能分配到m0.course\_1和m2.course\_2两个分片表中。这并不是我们期待的结果啊。我们是希望把数据分到四张表里。这时候怎么办？一种很自然的想法是调整分表的算法，让他按照4去轮询，定制分片算法 course\_$->{((cid+1)%4).intdiv(2)+1}。 这样简单看起来是没有问题的。如果ID是连续递增的，那么这个算法就可以将数据均匀的分到四个分片中。

![](./asserts/5.2.png)

这时，建议你将这个算法去结合ShardingSphere实际使用一下。下面是是示例配置：

```properties
# 打印SQL
spring.shardingsphere.props.sql-show = true
spring.main.allow-bean-definition-overriding = true

# ----------------数据源配置
# 指定对应的库
spring.shardingsphere.datasource.names=m0,m1

spring.shardingsphere.datasource.m0.type=com.alibaba.druid.pool.DruidDataSource
spring.shardingsphere.datasource.m0.driver-class-name=com.mysql.cj.jdbc.Driver
spring.shardingsphere.datasource.m0.url=jdbc:mysql://localhost:3306/coursedb?serverTimezone=UTC
spring.shardingsphere.datasource.m0.username=root
spring.shardingsphere.datasource.m0.password=root

spring.shardingsphere.datasource.m1.type=com.alibaba.druid.pool.DruidDataSource
spring.shardingsphere.datasource.m1.driver-class-name=com.mysql.cj.jdbc.Driver
spring.shardingsphere.datasource.m1.url=jdbc:mysql://localhost:3306/coursedb2?serverTimezone=UTC
spring.shardingsphere.datasource.m1.username=root
spring.shardingsphere.datasource.m1.password=root
#------------------------分布式序列算法配置
# 雪花算法，生成Long类型主键。
spring.shardingsphere.rules.sharding.key-generators.alg_snowflake.type=SNOWFLAKE
spring.shardingsphere.rules.sharding.key-generators.alg_snowflake.props.worker.id=1
# 指定分布式主键生成策略
spring.shardingsphere.rules.sharding.tables.course.key-generate-strategy.column=cid
spring.shardingsphere.rules.sharding.tables.course.key-generate-strategy.key-generator-name=alg_snowflake
#-----------------------配置实际分片节点
spring.shardingsphere.rules.sharding.tables.course.actual-data-nodes=m$->{0..1}.course_$->{1..2}
#MOD分库策略
spring.shardingsphere.rules.sharding.tables.course.database-strategy.standard.sharding-column=cid
spring.shardingsphere.rules.sharding.tables.course.database-strategy.standard.sharding-algorithm-name=course_db_alg

spring.shardingsphere.rules.sharding.sharding-algorithms.course_db_alg.type=MOD
spring.shardingsphere.rules.sharding.sharding-algorithms.course_db_alg.props.sharding-count=2
#给course表指定分表策略  standard-按单一分片键进行精确或范围分片
spring.shardingsphere.rules.sharding.tables.course.table-strategy.standard.sharding-column=cid
spring.shardingsphere.rules.sharding.tables.course.table-strategy.standard.sharding-algorithm-name=course_tbl_alg

# 分表策略-INLINE：按单一分片键分表
spring.shardingsphere.rules.sharding.sharding-algorithms.course_tbl_alg.type=INLINE
spring.shardingsphere.rules.sharding.sharding-algorithms.course_tbl_alg.props.algorithm-expression=course_$->{cid%2+1}
#这种算法如果cid是严格递增的，就可以将数据均匀分到四个片。但是雪花算法并不是严格递增的。
#如果需要做到均匀分片，修改算法同时，还要修改雪花算法。把SNOWFLAKE换成MYSNOWFLAKE
spring.shardingsphere.rules.sharding.sharding-algorithms.course_tbl_alg.props.algorithm-expression=course_$->{((cid+1)%4).intdiv(2)+1}

```

然后往course表里连续插入多条消息。

```java
@Test
public void addcourse() {
    for (int i = 0; i < 10; i++) {
        Course c = new Course();
        // Course表的主键字段cid交由雪花算法生成。
        c.setCname("java");
        c.setUserId(1001L);
        c.setCstatus("1");
        courseMapper.insert(c);
        // insert into course values ....
        System.out.println(c);
    }
}
```

那么你一定会发现，这十条course信息，很奇怪。库倒是分得挺均匀，但是表却分得很奇怪。就是没有办法插入到四张表的。只能插入到m0.course\_1和m2.course\_2两张表中。之前试了很多次，问了很多人，也查了很多资料，收效甚微。好像这只是我自己手气不好，自己瞎折腾出来的问题。一直想着是不是算法写错了？或者是运气问题，雪花算法因为某种不可知的神秘因素，不按我的预期生成数据。这应该也是很多人在学习ShardingSphere时经常遇到的问题。

直到后面，随着学习CosID框架的机会，深入梳理了一下分布式主键生成策略，才发现问题就出在雪花算法中。在ShardingSphere中扩展一个自己的雪花算法实现，才最终解决了这个问题。最后这问题细思极恐。雪花算法+取模分片，这应该是很多项目中都通用的一种分片策略。但是在这个场景下，雪花算法埋着一个大坑呢。这个大坑不可能只坑我一个人，应该坑到的是很多人，很多项目。

这到底是怎么回事呢？各位，咱们从头说起。
